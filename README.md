# Adaboost-vs-GradientBoosting-Cheese-Fat

Membandingkan performa Adaboost dan Gradient Boosting untuk klasifikasi kadar lemak keju dengan Feature Engineering, SMOTE dan strategi penanganan data hilang

## Dataset

Dataset yang digunakan dalam proyek ini adalah **"Canadian Cheese Directory"** yang bersumber dari Kaggle.

- **Sumber:** [Canadian Cheese Directory Dataset on Kaggle](https://www.kaggle.com/datasets/noahjanes/canadian-cheese-directory)
- **Deskripsi:** Dataset ini berisi 10 fitur untuk klasifikasi kadar lemak pada keju. Diantaranya 1 numerik kontinu, 2 data teks, 7 kategorikal.

## Diagram Alur Penelitian

Berikut adalah alur kerja yang dilakukan dalam penelitian ini:
![Diagram Alur Penelitian](assets/Alur-Diagram.png)

## Hasil Pengujian
Berdasarkan alur diagram diatas ada beberapa hal yang bisa dianalisa, yaitu :
### Apakah SMOTE akan meningkatkan akurasi ?
Analisis ini mencakup tiga tujuan utama. Pertama, mengevaluasi pengaruh penyeimbangan data terhadap peningkatan akurasi. Kedua, menguji algoritma mana yang menunjukkan stabilitas lebih tinggi terhadap penambahan data sintetis dari SMOTE. Ketiga, membandingkan performa model berdasarkan dua skenario penanganan data, yaitu skenario kualitas dan kuantitas. Penelitian ini membandingkan performa dua algoritma, AdaBoost dan Gradient Boosting, setelah data diseimbangkan dengan SMOTE. Hasilnya menunjukkan bahwa Gradient Boosting lebih unggul secara konsisten dan stabil dibandingkan AdaBoost. Secara keseluruhan, AdaBoost mengalami penurunan performa pada 46 dari 120 pengujian, sementara Gradient Boosting hanya menurun pada 5 kasus, menunjukkan ketahanan yang jauh lebih baik. Pola ini terlihat jelas baik di kelompok data tanpa FNC maupun dengan FNC, serta pada skenario penanganan data hilang (baik dengan menghapus baris atau mengisi nilai kosong).Penurunan kinerja AdaBoost dijelaskan karena algoritma ini terlalu sensitif terhadap data sintetis dari SMOTE, yang menyebabkan overfitting. Sebaliknya, Gradient Boosting mampu beradaptasi lebih baik terhadap data tambahan tanpa merusak struktur model yang sudah dipelajarinya. Oleh karena itu, Gradient Boosting dinilai sebagai pilihan yang lebih andal dan stabil dalam berbagai kondisi. Jadi SMOTE tidak selalu meningkatkan akurasi namun memiliki kencenderungan untuk meningkatakan ( lebih banyak yang meningkat akurasinya tapi tidak selalu, ada yang turun). 
### Apakah Feature Engineering bisa meningkatkan performa model ?
Akan di cek berdasarkan fitur 4,8,12,16,20,24,28. Penambahan fitur flavor dan karakteristik (FnC) terbukti memberi dampak positif yang konsisten terhadap algoritma AdaBoost. Dalam skenario kualitas maupun kuantitas, dataset dengan FnC unggul pada 20 dari total 28 konfigurasi, menunjukkan bahwa fitur ini sangat membantu meningkatkan kinerja klasifikasi AdaBoost. Sementara itu, Gradient Boosting menunjukkan respons yang lebih kompleks dan bervariasi. Pada skenario kualitas, justru dataset tanpa FnC lebih baik di 8 dari 14 kasus. Namun, pada skenario kuantitas, tren berbalik—fitur FnC justru lebih menguntungkan dengan kemenangan 9 dari 14. Jika digabungkan secara keseluruhan, dataset FnC menang di 35 dari 56 konfigurasi, jauh lebih banyak dibanding No FnC yang hanya menang 21 kali. Hal ini menegaskan bahwa meskipun efek pada Gradient Boosting tidak selalu konsisten, penambahan fitur FnC secara umum tetap memberi kontribusi positif, terutama pada algoritma AdaBoost, dan berpotensi signifikan dalam meningkatkan akurasi klasifikasi kadar lemak pada keju.
### Apakah meningkatnya jumlah fitur akan juga meningkatkan jumlah akurasi ?
Penambahan jumlah fitur tidak secara otomatis menjamin peningkatan akurasi. Hubungan antara keduanya lebih kompleks dan tidak selalu berjalan lurus. Setiap model dan dataset memiliki jumlah fitur optimal. Penambahan fitur hingga titik ini memang sangat bermanfaat karena memberikan informasi baru yang relevan bagi model untuk belajar. Namun, setelah melewati titik optimal tersebut, fitur-fitur tambahan berisiko lebih banyak membawa 'gangguan' (noise) dan kerumitan daripada informasi yang berguna. Akibatnya, performa model bisa stagnan atau bahkan menurun, seperti yang terbukti pada analisis dataset tanpa fitur kunci (No FnC). Oleh karena itu, faktor penentu yang paling krusial bukanlah sekadar jumlah fitur, melainkan kualitas dan relevansinya. Kehadiran fitur yang sangat kuat dan informatif (seperti pada dataset Dengan FnC) dapat membuat model lebih tangguh dan mampu memanfaatkan lebih banyak fitur secara efektif. Tanpa fitur berkualitas tersebut, model menjadi lebih rentan terhadap penurunan performa akibat penambahan fitur yang tidak relevan.
## Mana yang lebih baik, Modus vs Hapus : Penanganan Data Hilang
Secara keseluruhan, metode kualitas (menghapus data yang hilang) memberikan hasil yang jauh lebih unggul dibanding metode kuantitas (mengisi data dengan modus). Dari total 56 konfigurasi pengujian, metode kualitas menunjukkan performa lebih baik pada 52 konfigurasi, menandakan keunggulan yang sangat dominan. Namun, keunggulan ini datang dengan konsekuensi signifikan pada jumlah data. Metode kualitas hanya menyisakan 415 data, sedangkan metode kuantitas mempertahankan 659 data berkat proses imputasi. Selisih 244 data ini membuka kemungkinan munculnya pola baru yang tidak selalu valid atau representatif, karena data hasil imputasi bisa menambah noise atau pola buatan yang mengganggu proses pembelajaran model. Dengan demikian, meskipun metode kuantitas menjaga lebih banyak data, metode kualitas secara konsisten menghasilkan model yang lebih akurat dan andal, menunjukkan bahwa kebersihan dan kejelasan data lebih penting daripada sekadar kuantitas dalam konteks klasifikasi kadar lemak pada keju.
## Testing Model
Akan dipilih model terbaik adaboost dan gradient boosting dari metode kualitas maupun kuantitas. jadi akan ada 4 model yang diuji pada 30 data tes.
Berdasarkan hasil pengujian menunjukkan bahwa pendekatan berbasis kualitas data (menghapus data kosong) secara konsisten memberikan performa yang lebih unggul dibanding pendekatan kuantitas (mengisi dengan modus). Pada model AdaBoost, pendekatan kualitas menghasilkan akurasi 86,67%, jauh lebih tinggi dibanding kuantitas yang hanya mencapai 76,67%. Confusion matrix memperlihatkan bahwa pendekatan kualitas memiliki distribusi kesalahan yang lebih seimbang antar kelas. Sebaliknya, pendekatan kuantitas menunjukkan kecenderungan salah memprediksi kelas minoritas (higher fat) sebagai kelas mayoritas (lower fat). Hal yang sama juga terlihat pada Gradient Boosting, di mana pendekatan kualitas mencapai akurasi 93,33%, sementara pendekatan kuantitas hanya 83,33%. Kesalahan prediksi yang bias terhadap kelas mayoritas juga kembali muncul pada model berbasis kuantitas. Penyebab utama fenomena ini adalah metode imputasi dengan modus, yang berasal dari kelas mayoritas. Hal ini menyebabkan distorsi pada distribusi data, terutama pada kelas minoritas, sehingga merusak struktur pola asli dan menurunkan performa model. Dengan demikian, meskipun metode kuantitas mempertahankan jumlah data yang lebih besar, pendekatan kualitas tetap lebih efektif dalam menghasilkan model klasifikasi yang akurat dan adil.
## Kelemahan dari pengujian ini
- Preprocessing data teks untuk feature engineering, bisa dibilang untuk penangan data teks menjadi fitur-fitur baru ini terlalu sederhana, sehingga perlu di tinjau lebih lanjut. walaupun pada hasilnya menunjukan bahwa feature engineeringnya bisa meningkatkan perfoma namun hanya 35 dari 56 yaitu sekitar 62.5%. dengan meninjau preprocessing lebih lanjut mungkin bisa meningkatkan ratio ini.
- Pada tahap seleksi fitur, dipilih fitur-fitur terbaik tanpa melihat mutual information score, dan dipilih berurutan berdasarkan nilai tertinggi sehingga untuk bagian analis meningkatnya jumlah fitur akan juga meningkatkan jumlah akurasi, bisa dibuat bias, karena bisa saja saya memilih dari yang paling kecil nilainya dan ketika menambah fitur bisa memilih skor yang lebih tinggi yang akan mengakibatkan penggiringan narasi bahwa meningkatnya jumlah fitur akan juga meningkatkan jumlah akurasi.
## Yang bisa ditingkatkan dari pengujian ini
- Menangani nilai hilang  dengan pendekatan yang berbeda, yaitu tidak mengisi data dengan modus, melainkan mempertimbangkan metode penanganan lain agar informasi dalam data tetap terjaga seperti tehnik classification-based imputation. 
- Memanfaatkan parameter yang tersedia, pada penelitian ini kedua algoritma dijalankan secara default.
- Menggunakan metode feature selection lain selain mutual information, mengingat metode tersebut hanya mengukur hubungan antara satu fitur dengan label secara individual, tanpa mempertimbangkan interaksi antar fitur.
